## Email Campaign Effectiveness Prediction (Supervised Multiclass Classification Capstone Project)


# Problem Statement:
![rainbow](https://user-images.githubusercontent.com/75175373/153423947-b706cb4b-f598-4ca7-8eb5-4be41349bc30.png)

 Most of the small to medium business owners are making effective use of Gmail-based Email marketing Strategies for offline targeting of converting their prospective customers into leads so that they stay with them in Business. The main objective is to create a machine learning model to characterize the mail and track the mail that is ignored; read; acknowledged by the reader.

Email Campaign Effectiveness Prediction
These project is part of the ‚ÄúMachine Learning &Advanced Machine Learning‚Äù curriculum as capstone projects at AlmaBetter.

-- Project Status: [Completed]

Objective
The main objective is to create a machine learning model to characterize the mail and track the mail that is ignored; read; acknowledged by the reader. Most of the small to medium business owners are making effective use of Gmail-based Email marketing Strategies for offline targeting of converting their prospective customers into leads so that they stay with them in Business.
![rainbow](https://user-images.githubusercontent.com/75175373/153423947-b706cb4b-f598-4ca7-8eb5-4be41349bc30.png)

# üíæ Project Files Description

This Project includes 1 executable files, 1 presentation and 1 project documentation as follows:

### Executable Files:
Email_Campaign_Effectiveness_Prediction.ipynb Team Notebook - Complete notebook containing Data exploration/Data processing/transformation/model development.

### Presentation:
Email Campaign Effectiveness Prediction (1).pdf - Contains presentation i.e pptx of the project .

### Documentation:
Email Campaign Effectiveness Prediction_cohort_nilgiri.docx.pdf - Includes the documentation of the project.
![rainbow](https://user-images.githubusercontent.com/75175373/153423947-b706cb4b-f598-4ca7-8eb5-4be41349bc30.png)

### Methods Used
* Descriptive Statistics
* Data Visualization
* Machine Learning
### Technologies
* Python
* Pandas
* Numpy
* Matplotlib
* Seaborn
* Scikit-learn
* XGBoost

![rainbow](https://user-images.githubusercontent.com/75175373/153423947-b706cb4b-f598-4ca7-8eb5-4be41349bc30.png)
## Project Description
* EDA - Performed exploratory data analysis on numerical and categorical data.
* Data Cleaning - Missing value imputation,Outlier Treaatment
* Imabalance handling - First tried Under sampling and implemented baseline models then due to loss of information moved to different technique i.e oversampling using SMOTE and got better results.
* Feature Selection - Used information gain for feature selection and dropped features which had less information gain
Model development - Tried different model and finally compared all models F1 and roc_auc score.

![rainbow](https://user-images.githubusercontent.com/75175373/153423947-b706cb4b-f598-4ca7-8eb5-4be41349bc30.png)

# XGBoost
The library is laser focused on computational speed and model performance, as such there are few frills. Nevertheless, it does offer a number of advanced features.

 # Model Features
* The implementation of the model supports the features of the scikit-learn and R implementations, with new additions like regularization. Three main forms of gradient boosting are supported:

* Gradient Boosting algorithm also called gradient boosting machine including the learning rate. Stochastic Gradient Boosting with sub-sampling at the row, column and column per split levels. Regularized Gradient Boosting with both L1 and L2 regularization.

![rainbow](https://user-images.githubusercontent.com/75175373/153423947-b706cb4b-f598-4ca7-8eb5-4be41349bc30.png)

## System Features
The library provides a system for use in a range of computing environments, not least:

* Parallelization of tree construction using all of your CPU cores during training.
* Distributed Computing for training very large models using a cluster of machines.
* Out-of-Core Computing for very large datasets that don‚Äôt fit into memory.
* Cache Optimization of data structures and algorithm to make best use of hardware.
# Algorithm Features
* The implementation of the algorithm was engineered for efficiency of compute time and memory resources. A design goal was to make the best use of available resources to train the model. Some key algorithm implementation features include:
* Sparse Aware implementation with automatic handling of missing data values.
* Block Structure to support the parallelization of tree construction.
* Continued Training so that you can further boost an already fitted model on new data.
* XGBoost is free open source software available for use under the permissive Apache-2 license.

![rainbow](https://user-images.githubusercontent.com/75175373/153423947-b706cb4b-f598-4ca7-8eb5-4be41349bc30.png)

Needs of this project

* data exploration/descriptive statistics
* data processing/cleaning
* predictive modeling


# üìú Credits
Umesh Rathod | Avid Learner | Data Scientist | Machine Learning Engineer | Deep Learning enthusiast

Contact me for Data Science Project Collaborations
<a href="https://linkedin.com/in/https://www.linkedin.com/in/umesh-rathod-894720186/" target="blank"><img align="center" src="https://raw.githubusercontent.com/rahuldkjain/github-profile-readme-generator/master/src/images/icons/Social/linked-in-alt.svg" alt="https://www.linkedin.com/in/umesh-rathod-894720186/" height="30" width="40" /></a>
<a href="https://medium.com/@umesh.rathod1307" target="blank"><img align="center" src="https://raw.githubusercontent.com/rahuldkjain/github-profile-readme-generator/master/src/images/icons/Social/medium.svg" alt="@umesh.rathod1307" height="30" width="40" /></a>
</p>


![rainbow](https://user-images.githubusercontent.com/75175373/153423947-b706cb4b-f598-4ca7-8eb5-4be41349bc30.png)

üìö References
Jason Brownlee, 'Blog on XGBoost'. [Online].

Available: https://machinelearningmastery.com/gentle-introduction-xgboost-applied-machine-learning/

Wikipedia.org, 'XGBoost'. [Online].

Available: https://en.wikipedia.org/wiki/XGBoost

Youtube.com, 'XGBoost working'. [Online].

Available: https://www.youtube.com/watch?v=OQKQHNCVf5k

Manisha-sirsat.blogspot.com, 'What is Confusion Matrix and Advanced Classification Metrics?'. [Online].

Available: https://manisha-sirsat.blogspot.com/2019/04/confusion-matrix.html
![rainbow](https://user-images.githubusercontent.com/75175373/153423947-b706cb4b-f598-4ca7-8eb5-4be41349bc30.png)


